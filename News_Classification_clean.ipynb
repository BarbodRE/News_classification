{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysEb3xUvRJfn"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets evaluate scikit_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pT7BLaaCy3k9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5ZwUKj_epO4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaXiL7yoiOkt",
    "outputId": "c06490e7-c3ab-4320-e8b9-4ab0adf38ba7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"ag_news\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GW9hv9NS41fT"
   },
   "outputs": [],
   "source": [
    "small_train = dataset[\"train\"].shuffle(seed=42).select(range(20000))\n",
    "small_test = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v17h-dutiZzE"
   },
   "outputs": [],
   "source": [
    "model_name = \"prajjwal1/bert-tiny\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sROcAY8QisG4"
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "  return tokenizer(batch[\"text\"], padding=\"max_length\", truncation= True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "607ef91cb0304b3d87e3bf195d8b4362",
      "0a764b3df50249fe95ffc1f70f2b5648",
      "d0a2bcfddc504809ab2ff0667199e116",
      "88efdb0b6c754adbb563a98c6da32961",
      "ad2d984f235a4b088ad3bf056f50d5cb",
      "7f5da1c444c143b985cbd8947beb1cf9",
      "03b497bac41a401fa5d070f5e5f563c1",
      "c9d67f168b704cc9ab745e4bb51c036d",
      "d15f7276d2404f6da4f2ee195a03527c",
      "adc62586de9d43bcb4ae68a1a0504039",
      "fda9785c7a8849f480e631155a186d8c"
     ]
    },
    "id": "j6q-ZhElAAmM",
    "outputId": "71afafb3-4fe3-4081-a7be-4ab942834476"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607ef91cb0304b3d87e3bf195d8b4362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_train = small_train.map(tokenize, batched=True)\n",
    "small_test = small_test.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "424efe45f8e845d69534f1fcf7dd46b2",
      "8390a57b62aa4487a8ad1be8ba424c32",
      "191bd916bf904bb6ab4d365d31166486",
      "d87d7b442c3c4101a13233827bbd1ecf",
      "257ab413e120417581e1ede69bb48c79",
      "96fe9bb59dc04cbb811a8c5fbd9f10f4",
      "8dbac0f1626c458584cf9454a73d60e5",
      "37794dccb95f405dbbf0244dcd3b1418",
      "4949f85a807b4f1b9227f12b8a5610a6",
      "8509c286a9264c4498355ac52a2ee685",
      "61be7125ecf34535819acba3988e67e4"
     ]
    },
    "id": "MVs0zHVOjJ6q",
    "outputId": "06eb626a-d20f-4dd8-9300-50e65771a156"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424efe45f8e845d69534f1fcf7dd46b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsaNUSzNpZIc"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "#train_dataset = tokenized_datasets[\"train\"]\n",
    "#test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "9e3d2f2cf724490a9278c293803881e1",
      "7b983428604240d4ac181d2e4cd0b212",
      "b1055b4cecf14ea1b3aaa1dbfce85805",
      "fa2b7683f5e54b8cb4c238fcb70863fd",
      "ab3bc6334b474ab4bb7fb5ae9d839ceb",
      "0819aea24d2c466f9ac9138c4d71e7d2",
      "cb2f48d6fb7441c0b4360ef51ae9fb4f",
      "b5489695812143cdaa639a8648e1cf4e",
      "caa5a16a2c5041d89e32284728808076",
      "8b41283ab9b34c6ca9e8af2b9bd3bfbc",
      "fa1c7af74bca44a8bbf25fbfa60881b3",
      "454043c0be3949c9b961898a91eb2251",
      "5d5989493d5442c79a5cbebd5ab887bf",
      "39d17574a9b24b9c9f95f4cca81226b3",
      "b573c95bab8a4bfdaee4c259411df61a",
      "144b20fa90b54bf5babe4d466da30c1c",
      "244b6518d55e4dba97c7a7c64f175762",
      "6c403b48e17a42fc8770d1bf9f3e83d8",
      "5079ff98fea64236ae106be5dc423374",
      "ad313a625e944f29bf8a15fed3b269d0",
      "216096469d5342a2ba66cdfb0a9077b7",
      "ff0d6c23a8b54b82bcec049181b34edf"
     ]
    },
    "id": "gf0QoY1ikV3J",
    "outputId": "db895936-05e3-47ce-87db-947d5b2987d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3d2f2cf724490a9278c293803881e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454043c0be3949c9b961898a91eb2251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJaeQxBnkpJC"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Jyo2Fj8lFY3"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  logits, labels = eval_pred\n",
    "  preds = np.argmax(logits, axis=-1)\n",
    "  return{\n",
    "      \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "      \"precision\": precision.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Gd6BJr-mQHC",
    "outputId": "63605ec7-01dd-4c09-baf6-6de134718d99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results_news\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    num_train_epochs = 1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    fp16 = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rd-SIlNnShH",
    "outputId": "63ed09a9-1b3b-4953-bfea-5bd6b31ee359"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1871744232.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = small_train,\n",
    "    eval_dataset = small_test,\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "8IHRz3YuqZg4",
    "outputId": "9fb493c6-be85-4c3f-9f09-925b49b74235"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 04:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.689200</td>\n",
       "      <td>0.658160</td>\n",
       "      <td>0.846447</td>\n",
       "      <td>0.845653</td>\n",
       "      <td>0.846447</td>\n",
       "      <td>0.844273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…ÙˆØ²Ø´ ===\n",
      "TrainOutput(global_step=1250, training_loss=0.892452896118164, metrics={'train_runtime': 280.3797, 'train_samples_per_second': 71.332, 'train_steps_per_second': 4.458, 'total_flos': 6356398080000.0, 'train_loss': 0.892452896118164, 'epoch': 1.0})\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "print(\"\\n === Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…ÙˆØ²Ø´ ===\")\n",
    "print(train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "wdHZX8utKj4O",
    "outputId": "9ebdcd06-7913-4825-8ae4-f635542ee331"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='950' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [475/475 33:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ (Test) ===\n",
      "eval_loss: 0.6582\n",
      "eval_accuracy: 0.8464\n",
      "eval_precision: 0.8457\n",
      "eval_recall: 0.8464\n",
      "eval_f1: 0.8443\n",
      "eval_runtime: 31.2503\n",
      "eval_samples_per_second: 243.1980\n",
      "eval_steps_per_second: 15.2000\n",
      "epoch: 1.0000\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(\"\\n=== Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ (Test) ===\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "4GtoiArcs7UA",
    "outputId": "e0dc6032-715e-442d-bb67-5892f2d871b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(small_test)\n",
    "y_true = preds.label_ids\n",
    "y_pred = np.argmax(preds.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymSrVATatzak",
    "outputId": "689ae69f-4e31-4dfc-8cac-21a49da4b8d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.85      0.88      0.86      1900\n",
      "      Sports       0.91      0.96      0.93      1900\n",
      "    Business       0.83      0.70      0.76      1900\n",
      "    Sci/Tech       0.80      0.84      0.82      1900\n",
      "\n",
      "    accuracy                           0.85      7600\n",
      "   macro avg       0.85      0.85      0.84      7600\n",
      "weighted avg       0.85      0.85      0.84      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ===\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5PPcujaw5bX",
    "outputId": "f29cb50f-9283-4d74-e218-7ec2b4c0be18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Ù…Ø§ØªØ±ÛŒØ³ Ø³Ø±Ø¯Ø±Ú¯Ù…ÛŒ===\n",
      "[[1672   88   92   48]\n",
      " [  45 1826   17   12]\n",
      " [ 169   46 1333  352]\n",
      " [  83   51  164 1602]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===Ù…Ø§ØªØ±ÛŒØ³ Ø³Ø±Ø¯Ø±Ú¯Ù…ÛŒ===\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWUh7_tGxP_v",
    "outputId": "bfca5474-a60d-4d68-9a79-357b2139de89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===10 Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø² ØªØ³Øª===\n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡1| gold=0|pred=1 --- \n",
      "Vilsack, Dean Jockey for Top DNC Post (AP) AP - Iowa Gov. Tom Vilsack told Democratic leaders on Friday he may seek the party's top job as the jockeying to replace chairman Terry McAuliffe intensified.\n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡2| gold=3|pred=1 --- \n",
      "Rough ride won #39;t stop next X Prize shot The rolling experienced by SpaceShipOne on its first Ansari X Prize flight on Wednesday will not jeopardise the team #39;s chances of winning the \\$10 million purse, team members said in a post-flight briefing.\n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡3| gold=1|pred=2 --- \n",
      "HONDA LINKED WITH BAR TAKEOVER BAR #39;s engine partner Honda is believed to be interested in purchasing the Brackley team and a deal could be done within the next 12 months.\n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡4| gold=2|pred=0 --- \n",
      "Nobel Economics Prize Awarded Norwegian-born Finn Kydland and Edward Prescott of the United States won the 2004 Nobel\\economics prize, the Royal Swedish Academy of Sciences said on Monday.\n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡5| gold=0|pred=1 --- \n",
      "Live: Olympics day four Richard Faulds and Stephen Parry are going for gold for Great Britain on day four in Athens.\n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡6| gold=0|pred=1 --- \n",
      "Bush video awarded Turner Prize Artist Jeremy Deller wins this year's Turner Prize for a film about US President George Bush's home town.\n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡7| gold=2|pred=0 --- \n",
      "Indian PM pledges to protect poor from oil-driven inflation NEW DELHI : Indian Prime Minister Manmohan Singh pledged to try to shield the poor by keeping down prices of essential goods amid rising inflation.\n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡8| gold=3|pred=1 --- \n",
      "Rocky Legends; Tony Hawk's Underground 2; Nisus Writer Express 2.0; Surfsaver 6 This is the second Rocky video game in two years -- even though it's been 14 years since the last \"Rocky\" flick.\n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡9| gold=2|pred=3 --- \n",
      "PeopleSoft sweetens employee compensation Business software maker PeopleSoft Friday said it was boosting compensation packages for all employees except its chief executive in a move that would raise the \n",
      "\n",
      " --- Ù†Ù…ÙˆÙ†Ù‡10| gold=3|pred=1 --- \n",
      "SpaceShipOne Rolls Toward Victory MOJAVE, California -- A Southern California aerospace team took a big step toward capturing the \\$10 million Ansari X Prize Wednesday, but not without surviving a scary moment when the pilot found himself in a rapid spin as he roared across the threshold \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===10 Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø² ØªØ³Øª===\")\n",
    "wrong_idx = np.where(y_true != y_pred)[0]\n",
    "samples = random.sample(list(wrong_idx), 10)\n",
    "for i , idx in enumerate(samples):\n",
    "  idx = int(idx)\n",
    "  text = dataset[\"test\"][idx][\"text\"][:300]\n",
    "  gold = dataset[\"test\"][idx][\"label\"]\n",
    "  pred = y_pred[idx]\n",
    "  print(f\"\\n --- Ù†Ù…ÙˆÙ†Ù‡{i+1}| gold={gold}|pred={pred} --- \\n{text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

# === Demo: Try the model with custom input ===

from transformers import pipeline

# Load fine-tuned model (use the model and tokenizer you trained)
demo_clf = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Map category ids to names
id2label = {
    0: "World ğŸŒ",
    1: "Sports ğŸ…",
    2: "Business ğŸ’¼",
    3: "Science/Technology ğŸ”¬"
}

# Example input
sample_text = "Google announced a breakthrough in quantum computing technology."
pred = demo_clf(sample_text, truncation=True)[0]

print(f"ğŸ“° Input Text: {sample_text}")
print(f"âœ… Predicted Category: {id2label[int(pred['label'].split('_')[-1])]}")
